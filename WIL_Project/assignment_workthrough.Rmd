---
title: "R Notebook"
output:
  html_notebook: default
  pdf_document: default
---

```{r}
#setup chunk
library(readr)
library(tidyr)
library(dplyr)
library(caret)
library(purrr)
library(lubridate)
library(ggplot2)
```

#Read and Join Data
```{r}
CUSTOMER_LOAN <- read_csv('~/repos/MXB344/WIL_Project/data/CUSTOMER_LOAN.csv')
CUSTOMER_LOAN_HISTORY <- read_csv('~/repos/MXB344/WIL_Project/data/CUSTOMER_LOAN_HISTORY.csv')

PROJECT_DATA <- 
  left_join(CUSTOMER_LOAN, CUSTOMER_LOAN_HISTORY, by=c("id","member_id") )

project_data_tst <- 
  (!duplicated(PROJECT_DATA)) %>%
  PROJECT_DATA[.,] %>% 
  filter(!is.na(earliest_cr_line))
```
38524 Obersations

#Create a response variable
```{r}
project_data_tst <-
  project_data_tst %>% 
    mutate(repay_fail = if_else(loan_status %in% c('Charged Off',
                                                   'Does not meet the credit policy. Status:Charged Off',
                                                   'Late (31-120 days)',
                                                   'Late (16-30 days)',
                                                   'Default'), true=1, false=0))


```

#Variable selection
##Remove Low Variance
```{r}
#Remove columns with near zero variance
#Captures NAs and constants(?)
nearZeroVarCols <- caret::nearZeroVar(project_data_tst)
names(project_data_tst)[nearZeroVarCols] %>% length() #67 near zero variance predictors
project_data_tst <- project_data_tst[,-nearZeroVarCols]
#misses some NA columns.
```
##Remove unique categories
```{r}
#Remove columns with unique values for all rows
#url, desc, title, emp_title
#We could try and engineer features from these or we can toss.
project_data_tst <- 
  project_data_tst %>% select(-url, -desc, -emp_title, -title)

table(project_data_tst$zip_code)
# We can see many zip codes only have a handful of observations
# There are a number with a few hundred. If we wanted to explore the effects of those we could recode:
# category_of_interest1, category_of_interest3, other etc..
# we have no reason to believe zip code is an imoprtant so fpr now we remove.
project_data_tst <- 
  project_data_tst %>% select(-zip_code)
```
##Convert strings to numeric
```{r}
#Need to convert some string variable to numeric
#Revo util has a percentage sign
project_data_tst <- 
  project_data_tst %>% 
    mutate(revol_util = as.numeric(gsub(pattern = "%", replacement = "", x = revol_util))/100)
```
##Handle NA values

Proportion of NAs by variable:

```{r}
#High proportion of NA
missing <- 
  dmap(project_data_tst, .f = is.na) %>% 
  dmap(sum) %>% 
  dmap(function(x){x/nrow(project_data_tst)}) %>% 
  gather(key="column",
         value="missing",
         gather=id:repay_fail) %>%
  arrange(desc(missing))
missing %>% View()
#
```

In handling NAs we can either:

* Remove column
* Impute
* Transform column

Suggest Remove:
mths_since_last_major_derog
mths_since_last_record
next_payment_d - although you could transform this to something like 'delinq_last_6months'.

#Handling NA for logistic regression
```{r}
#Removing Very high
project_data_tst <- 
  project_data_tst %>% select(-mths_since_last_major_derog, -mths_since_last_record, -next_pymnt_d)

#could coalesce mths_since_last_delinq into delinq in last 6 months or such. But we have the Delinq last 2 years varibale which is probably sufficient.
#Last payment date is probably not important since we already have a variable for if the loan is late, 16-30, 31-120 etc.
#Last credit pull is probably not useful - I thnk this relates to the blanked credit rating variables.
#id, member id should not be included.
project_data_tst <- 
  project_data_tst %>% select(-mths_since_last_delinq, -last_pymnt_d, -last_credit_pull_d, -id, -member_id)

#revol_util is an intersting one. Data dictionary says:
#Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.
#Wiki definition suggests this is like credit card debt.
#This could be an important variable.
project_data_tst %>% filter(is.na(revol_util)) %>% View()
#It's a low number of NAs, only 54. So it makes sense just to remove.
project_data_tst <- 
  project_data_tst %>% filter(!is.na(revol_util))

project_data_tst %>% nrow()
```
#Date Variables
```{r}
#It's not great to have dates. Really we want to convert them to some number of months since event.

#convert earliest credit line and date approved to credit age
project_data_tst <- 
  project_data_tst %>% mutate(credit_age_yrs = difftime(
                                              parse_date_time(paste0('1',issue_d), orders="d!bY!"),
                                              parse_date_time(paste0('1',earliest_cr_line), orders="d!bY!"),
                                              units = 'weeks'
                                            )/52
                        ) %>%
  select(-issue_d, -earliest_cr_line)

```
#Leaking Variables
```{r}
#Consider removing rating and rate variables.
#A couple of issues arise
#1. the Alpha grade columns are linear combinations of the sub_grade columns
#2. the model perfectly separates repay_fail?
## recoveries > 0 separates repay fail perfectly.
project_data_tst <-
  project_data_tst %>% select(-recoveries, -grade, -loan_status, -sub_grade)
```


#Correlated Variables
```{r}

#In order to find correlation we would need to convert all variables to numeric/indicators
varcoding <- dummyVars(repay_fail ~ . ,data = project_data_tst,fullRank = T)
train_data <- predict(varcoding, newdata = project_data_tst)
dim(train_data) #981 colums
#Identify high correlations
cor_train_data <- cor(train_data)
findCorrelation(cor_train_data, names=TRUE)

#is there anything correlated perfectly with response?
cor_train_data_reposonse = cor(cbind(project_data_tst$repay_fail, train_data))
findCorrelation(cor_train_data_reposonse, names=TRUE)
#No.
```
## Drop correlated columns
```{r}
train_data <- train_data[,-findCorrelation(cor_train_data, names=FALSE)]
dim(train_data)
```


#Variable Importance
```{r}
caret::varImp(model_fit)
```


#Fit GLM
#Fit
```{r}

train_frame <- cbind.data.frame(repay_fail = project_data_tst$repay_fail, as.data.frame(train_data))

model_fit <- glm(data = train_frame,
    formula = repay_fail ~ .,
  family = "binomial",
  control = glm.control(maxit = 50))

#This model get's perfect linear separation if you include the grades.
## Specificall mention this scenario!: Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

model_preds = 1 / (1+ (1/exp(predict(model_fit)) ) )

model_preds[model_preds > 0.5] <- 1
model_preds[model_preds <= 0.5] <- 0

caret::confusionMatrix(data = model_preds, reference = project_data_tst$repay_fail)

```

<!-- What I am thinking is Option 3. This is for several reasons: -->

<!-- Introduce Kaggle to the students -->
<!-- However the data size is too big which means classical statistics (eg p-values) will fail -->
<!-- Consequently, I am proposing to modify the dataset such that it has say around 5,000 observations only -->
<!-- Around the "max" where you can relay on p-values but big enough to look for an alternative measures -->
<!-- Add "test data" (or other unusual data) into the dataset which the students need to identify and remove -->
<!-- Make some records contain missing values -->
<!-- Add a couple categorical variables -->
<!-- Assignment can be very similar to the insurance group? assignment from a few years ago (ie a pretty standard assignment) but with the following changes: -->

<!-- Similar to prior assignments, the student needs to run all three models: logit, probit, and cloglog -->
<!-- Goodness of fit - likelihood ratio, scaled deviance, etc -->
<!-- Model adequacy - look at transformation, add interaction, residual, etc -->
<!-- Final model selection -->
<!-- However, the key additions to the assignment are: -->

<!-- Large Dataset: -->
<!-- Discuss the impact to p-value for example when dealing with large dataset -->
<!-- Make use of validation sample - this "machine learning" concept is not currently being taught in maths -->
<!-- Use of Gini and Information Value (IV) in addition to p-value -->
<!-- Data Issue: -->
<!-- Need to handle special values, missing values, etc -->
<!-- Need to exclude "test" or staff observations for example -->
<!-- Business: -->
<!-- Why the industry may prefer one model (ie logit) over others? Because the output is often a scorecard, but the student will not be convert the model to a scorecard else the project will be way too long -->
<!-- Talk about the variables. The student should think about what other variables might be useful that are not in the dataset. The reason is that in the industry, we often need to construct the modelling dataset ourselves. Some literature review/paper searching will be good for maths student who most likely has not used database before -->




